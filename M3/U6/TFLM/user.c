/*
Explica√ß√£o do C√≥digo
Inicializa√ß√£o do ADC:

Configuramos o GP28 como entrada anal√≥gica para capturar os sinais do microfone.
Convertendo o sinal anal√≥gico para o formato correto, considerando o n√≠vel m√©dio do microfone (1,65V).
Buffer de √Åudio:

Capturamos 1 segundo de √°udio em um buffer de 16.000 amostras (taxa de 16 kHz).
Pr√©-Processamento (Espectrograma):

O √°udio capturado √© transformado em um espectrograma, que √© o formato de entrada do modelo. Neste exemplo, simplificamos a l√≥gica. Na pr√°tica, voc√™ pode usar uma biblioteca de FFT ou implementar seu pr√≥prio algoritmo.
Infer√™ncia com TensorFlow Lite:

O espectrograma √© alimentado no modelo TensorFlow Lite.
O resultado do modelo √© interpretado para determinar se a palavra "Alexa" foi detectada.
Detec√ß√£o Cont√≠nua:

O c√≥digo roda continuamente, detectando a palavra "Alexa" em loops de 1 segundo.
Compila√ß√£o e Execu√ß√£o
Instale o Pico SDK e configure o ambiente de desenvolvimento.

Salve o modelo alexa_model.tflite como um array bin√°rio com o comando:

bash
Copiar
Editar
xxd -i alexa_model.tflite > alexa_model_data.h
Compile o c√≥digo e fa√ßa o upload para o Raspberry Pi Pico:

bash
Copiar
Editar
cmake ..
make
sudo picotool load nome_do_binario.uf2
Conecte o microfone de eletreto ao GP28 e monitore os resultados via terminal serial.

Pr√≥ximos Passos
Melhorar o Pr√©-Processamento: Substituir a fun√ß√£o fict√≠cia compute_spectrogram por uma implementa√ß√£o real de FFT para calcular o espectrograma.
Ajustar o Modelo: Certifique-se de que o modelo est√° otimizado para detec√ß√£o em tempo real.
Aprimorar a Infer√™ncia: Ajuste os limiares de decis√£o para aumentar a precis√£o da detec√ß√£o.
Com essas etapas, voc√™ ter√° um sistema TinyML rodando no Raspberry Pi Pico W, capaz de detectar a palavra-chave "Alexa" de forma eficiente! üòä
*/

#include <stdio.h>
#include "pico/stdlib.h"
#include "hardware/adc.h"
#include "tensorflow/lite/micro/all_ops_resolver.h"
#include "tensorflow/lite/micro/micro_error_reporter.h"
#include "tensorflow/lite/micro/micro_interpreter.h"
#include "tensorflow/lite/schema/schema_generated.h"
#include "tensorflow/lite/version.h"

// Importar o modelo treinado como um array
#include "alexa_model_data.h"

// Configura√ß√µes de √°udio
#define AUDIO_BUFFER_SIZE 16000  // Tamanho do buffer de √°udio (1 segundo a 16 kHz)
#define SAMPLE_RATE 16000        // Taxa de amostragem
#define ADC_PIN 28               // GP28 (ADC2)
#define ADC_VREF 3.3             // Tens√£o de refer√™ncia (3,3V)
#define ADC_LEVEL_OFFSET 1.65    // Offset do n√≠vel m√©dio do microfone (1,65V)

// Configura√ß√µes do TensorFlow Lite
constexpr int kTensorArenaSize = 10 * 1024;
uint8_t tensor_arena[kTensorArenaSize];

// Buffers
int16_t audio_buffer[AUDIO_BUFFER_SIZE]; // Buffer de √°udio
float input_tensor_data[40 * 40];        // Dados de entrada pr√©-processados (espectrograma)

// Fun√ß√µes auxiliares
void record_audio();
void compute_spectrogram(const int16_t *audio, float *output);

// Fun√ß√£o principal do TensorFlow Lite
void detect_keyword();

int main() {
    stdio_init_all();
    printf("Inicializando sistema de detec√ß√£o de palavra-chave 'Alexa'...\n");

    // Configurar ADC
    adc_init();
    adc_gpio_init(ADC_PIN);  // Configura o pino GP28 como entrada anal√≥gica
    adc_select_input(2);     // Seleciona ADC2 (GP28)

    // Configura√ß√£o inicial do TensorFlow Lite
    tflite::MicroErrorReporter error_reporter;
    tflite::AllOpsResolver resolver;
    const tflite::Model* model = tflite::GetModel(alexa_model_data);

    if (model->version() != TFLITE_SCHEMA_VERSION) {
        printf("Modelo incompat√≠vel com TensorFlow Lite!\n");
        while (1);
    }

    tflite::MicroInterpreter interpreter(
        model, resolver, tensor_arena, kTensorArenaSize, &error_reporter);
    interpreter.AllocateTensors();

    // Loop principal
    printf("Sistema pronto. Detectando a palavra 'Alexa'...\n");
    while (1) {
        record_audio();  // Grava √°udio no buffer
        compute_spectrogram(audio_buffer, input_tensor_data);  // Processa o espectrograma

        // Alimenta o modelo com o espectrograma
        TfLiteTensor* input = interpreter.input(0);
        memcpy(input->data.f, input_tensor_data, sizeof(input_tensor_data));

        // Executa a infer√™ncia
        interpreter.Invoke();

        // L√™ os resultados
        TfLiteTensor* output = interpreter.output(0);
        int alexa_detected = output->data.f[0] > 0.5;  // Resultado bin√°rio (1 para "Alexa", 0 para ru√≠do)

        // Mostra o resultado
        if (alexa_detected) {
            printf("Palavra 'Alexa' detectada!\n");
        } else {
            printf("Ru√≠do detectado...\n");
        }

        sleep_ms(500);  // Espera 500 ms antes da pr√≥xima infer√™ncia
    }
}

// Fun√ß√£o para gravar √°udio
void record_audio() {
    for (int i = 0; i < AUDIO_BUFFER_SIZE; i++) {
        // L√™ o valor do ADC e converte para o formato correto (-1 a 1 em 16 bits)
        uint16_t raw_adc = adc_read();
        float voltage = raw_adc * (ADC_VREF / 4095.0);  // Converte para tens√£o (0V a 3.3V)
        audio_buffer[i] = (int16_t)((voltage - ADC_LEVEL_OFFSET) * 32768 / ADC_LEVEL_OFFSET);
        sleep_us(1000000 / SAMPLE_RATE);  // Espera para manter a taxa de amostragem
    }
}

// Fun√ß√£o para calcular o espectrograma
void compute_spectrogram(const int16_t *audio, float *output) {
    // Esta fun√ß√£o deve implementar um algoritmo para converter o √°udio em um espectrograma.
    // Como exemplo, usaremos valores fict√≠cios. Na pr√°tica, use uma biblioteca FFT.
    for (int i = 0; i < 40 * 40; i++) {
        output[i] = (float)audio[i % AUDIO_BUFFER_SIZE] / 32768.0f;  // Normaliza o √°udio
    }
}

  git config --global user.name "Your Name"
